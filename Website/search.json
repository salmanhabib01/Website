[
  {
    "objectID": "Assignments/Assignment2.html",
    "href": "Assignments/Assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "library(gtrendsR)\n\nWarning: package 'gtrendsR' was built under R version 4.4.2\n\nHarrisTrumpElection &lt;- gtrends(\n  c(\"Trump\", \"Harris\", \"election\"), \n  time = \"2024-01-01 2024-10-01\"\n)\nHarris_Trump_Election_interest_over_time &lt;- HarrisTrumpElection$interest_over_time\n\ntrump_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"Trump\")\nharris_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"Harris\")\nelection_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"election\")\n\npar(family = \"serif\")\nplot(\n  trump_data$date, trump_data$hits, \n  type = \"l\", col = \"blue\", \n  xlab = \"Date\", ylab = \"Search Interest\", \n  main = \"Google Trends: Trump, Harris, and Election\",\n  lwd = 2 \n)\n\nlines(\n  harris_data$date, harris_data$hits, \n  col = \"red\", lwd = 2\n)\n\nlines(\n  election_data$date, election_data$hits, \n  col = \"green\", lwd = 2\n)\n\nlegend(\n  \"topright\", legend = c(\"Trump\", \"Harris\", \"Election\"), \n  col = c(\"blue\", \"red\", \"green\"), lty = 1, lwd = 2\n)"
  },
  {
    "objectID": "Assignments/Assignment3.html",
    "href": "Assignments/Assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "library(quanteda)\n\nWarning: package 'quanteda' was built under R version 4.4.2\n\n\nPackage version: 4.1.0\nUnicode version: 15.1\nICU version: 74.1\n\n\nParallel computing: 4 of 4 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\n\nWarning: package 'quanteda.textmodels' was built under R version 4.4.2\n\nlibrary(quanteda.textplots)\n\nWarning: package 'quanteda.textplots' was built under R version 4.4.2\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.4.2\n\nsummit &lt;- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm &lt;- dfm(toks)\nclass(toks)\n\n[1] \"tokens\"\n\nsum_lsa &lt;- textmodel_lsa(sumtwtdfm, nd=4,  margin = c(\"both\", \"documents\", \"features\"))\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                      4 -none-    numeric\ndocs                58080 -none-    numeric\nfeatures            63972 -none-    numeric\nmatrix_low_rank 232218360 -none-    numeric\ndata            232218360 dgCMatrix S4     \n\nhead(sum_lsa$docs)\n\n              [,1]          [,2]          [,3]          [,4]\ntext1 8.670375e-03  9.539431e-03 -3.365261e-03  1.378640e-02\ntext2 8.662406e-06 -8.754517e-06 -6.159723e-06  1.673892e-05\ntext3 2.917454e-03  6.809891e-03  1.059921e-03 -3.180288e-03\ntext4 1.046103e-02  8.782783e-04 -4.359418e-03  4.941183e-03\ntext5 3.247147e-03  8.006068e-03  1.632191e-04 -4.657788e-03\ntext6 3.247147e-03  8.006068e-03  1.632191e-04 -4.657788e-03\n\nclass(sum_lsa)\n\n[1] \"textmodel_lsa\"\n\ntweet_dfm &lt;- tokens(sum_twt, remove_punct = TRUE) %&gt;%\n  dfm()\nhead(tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 15,927 features (99.89% sparse) and 0 docvars.\n       features\ndocs    breaking news us president biden amp communist china leader xi\n  text1        1    1  1         1     1   1         1     2      1  1\n  text2        0    0  0         0     0   0         0     0      0  0\n  text3        0    0  0         0     1   0         0     0      0  1\n  text4        0    0  0         1     1   0         0     0      0  1\n  text5        0    0  0         0     1   0         0     0      0  1\n  text6        0    0  0         0     1   0         0     0      0  1\n[ reached max_nfeat ... 15,917 more features ]\n\n\nThe table represents a document-feature matrix (DFM), summarizing the frequency of unique tokens (features) in six tweets (documents). Each row corresponds to a tweet, and each column represents a token. For example, in the first tweet (text1), the token biden appears once, while tokens like breaking and news also appear once. Most entries in the matrix are zeros, as only a few tokens appear in any given tweet, resulting in 99.89% sparsity. The displayed table shows only the first 10 features out of 15,927. This matrix serves as the basis for further analysis, such as extracting hashtags, mentions, or analyzing relationships between tokens.\n\ntag_dfm &lt;- dfm_select(tweet_dfm, pattern = \"#*\")\ntoptag &lt;- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"       \"#biden\"       \"#xijinping\"   \"#joebiden\"    \"#america\"    \n [6] \"#americans\"   \"#coronavirus\" \"#fentanyl\"    \"#xi\"          \"#us\"         \n\n\nThe top hashtags reflect the main themes of the Biden-Xi summit discussed on Twitter. The frequent appearance of hashtags like #china, #biden, #xijinping, and #joebiden highlights the focus on the leaders and countries involved. Hashtags such as #america, #americans, and #us indicate attention on U.S.-related topics, while #coronavirus and #fentanyl suggest discussions about global health and the drug crisis as significant issues tied to the event.\n\ntag_fcm &lt;- fcm(tag_dfm)\nhead(tag_fcm)\n\nFeature co-occurrence matrix of: 6 by 665 features.\n               features\nfeatures        #breaking #breakingnews #biden #china #usa #pray4america\n  #breaking             0             4      5      5    5             0\n  #breakingnews         0             0      4      5    4             0\n  #biden                0             0      0    443   49             0\n  #china                0             0      0      8   76             0\n  #usa                  0             0      0      0    6             0\n  #pray4america         0             0      0      0    0             0\n               features\nfeatures        #joebiden #xijinping #america #americans\n  #breaking             0          0        0          0\n  #breakingnews         0          0        0          0\n  #biden              299        370      302        295\n  #china              339        434      308        295\n  #usa                 12         15        0          0\n  #pray4america         0          0        0          0\n[ reached max_nfeat ... 655 more features ]\n\ntopgat_fcm &lt;- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 1)\n\n\n\n\n\n\n\n\nThe network graph illustrates the co-occurrence of hashtags in tweets about the Biden-Xi summit, revealing key themes and focal points of discussion. Central hashtags like #china, #biden, and #america dominate the conversation, emphasizing the prominence of U.S.-China relations. Clusters of hashtags reflect distinct topics: one group discusses international relations and issues like #coronavirus and #fentanyl, while another highlights human rights concerns with hashtags such as #uyghurs, #uyghurgenocide, and #humanrights. The connections between hashtags demonstrate the multidimensional nature of the discourse, with strong ties between geopolitical and humanitarian topics.\n\nuser_dfm &lt;- dfm_select(tweet_dfm, pattern = \"@*\")\ntopuser &lt;- names(topfeatures(user_dfm, 50))\nhead(topuser, 20)\n\n [1] \"@potus\"           \"@politico\"        \"@joebiden\"        \"@jendeben\"       \n [5] \"@eneskanter\"      \"@nwadhams\"        \"@phelimkine\"      \"@nahaltoosi\"     \n [9] \"@nba\"             \"@washwizards\"     \"@pelicansnba\"     \"@capitalonearena\"\n[13] \"@kevinliptakcnn\"  \"@foxbusiness\"     \"@morningsmaria\"   \"@scmpnews\"       \n[17] \"@petermartin_pcm\" \"@nytimes\"         \"@uyghur_american\" \"@kaylatausche\"   \n\nuser_fcm &lt;- fcm(user_dfm)\nhead(user_fcm, 20)\n\nFeature co-occurrence matrix of: 20 by 711 features.\n                 features\nfeatures          @youtube @bfmtv @cnn @lauhaim @barackobama @joebiden\n  @youtube               0      0    0        0            0         0\n  @bfmtv                 0      0    1        1            1         1\n  @cnn                   0      0    0        1            1         1\n  @lauhaim               0      0    0        0            1         1\n  @barackobama           0      0    0        0            0         1\n  @joebiden              0      0    0        0            0         3\n  @kamalaharris          0      0    0        0            0         0\n  @hillaryclinton        0      0    0        0            0         0\n  @billclinton           0      0    0        0            0         0\n  @cbsnews               0      0    0        0            0         0\n                 features\nfeatures          @kamalaharris @hillaryclinton @billclinton @cbsnews\n  @youtube                    0               0            0        0\n  @bfmtv                      1               1            1        1\n  @cnn                        1               1            1        1\n  @lauhaim                    1               1            1        1\n  @barackobama                1               1            1        1\n  @joebiden                   1               1            1        1\n  @kamalaharris               0               1            1        1\n  @hillaryclinton             0               0            1        1\n  @billclinton                0               0            0        1\n  @cbsnews                    0               0            0        0\n[ reached max_feat ... 10 more features, reached max_nfeat ... 701 more features ]\n\n\nThe table presents a feature co-occurrence matrix (FCM) of Twitter mentions, showing how frequently certain user handles (e.g., @joebiden, @cnn, @nytimes) appear together in tweets about the Biden-Xi summit. The first list highlights the top 20 most frequently mentioned user handles, including influential figures and organizations such as @potus, @joebiden, and @nytimes. The matrix shows co-occurrence counts between these handles and others, where rows and columns represent specific handles. For example, @joebiden co-occurs three times with itself, while it co-occurs once with handles like @barackobama and @cnn. Handles with no shared mentions in the dataset have zeros in their corresponding cells. This co-occurrence data reflects the focus on key public figures, media outlets, and organizations involved in discussions related to the summit, highlighting their interconnected roles in shaping the narrative.\n\nuser_fcm &lt;- fcm_select(user_fcm, pattern = topuser)\ntextplot_network(user_fcm, min_freq = 20, edge_color = \"firebrick\", edge_alpha = 0.8, edge_size = 1)\n\n\n\n\n\n\n\n\nThe network graph illustrates the co-occurrence of Twitter mentions in discussions about the Biden-Xi summit, with distinct clusters reflecting subtopics. A dense sports-related cluster includes handles like @nba, @washwizards, and @capitalonearena, possibly indicating discussions on sports diplomacy. Another cluster involving @politico, @nahaltoosi, and @phelimkine suggests political or journalistic coverage, while mentions like @foxbusiness and @morningsmaria point to economic or business-related topics. The strength of connections varies, with some pairs, such as @nba and @washwizards, showing frequent co-mentions, while smaller, isolated pairs like @learyreports and @glubold represent narrower discussions. Overall, the graph highlights the segmented yet interconnected nature of conversations around the summit.\n\ndfm_inaug &lt;- data_corpus_inaugural %&gt;%\n  corpus_subset(Year &lt;= 1826) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_trim(min_termfreq = 10)\n\nset.seed(123)  # For reproducibility\ntextplot_wordcloud(dfm_inaug, min_count = 10, \n                   color = c(\"red\", \"blue\", \"green\", \"purple\"))\n\n\n\n\n\n\n\n\nThis wordcloud visualizes the most frequently used words in U.S. presidential inaugural addresses from 1789 to 1826, with the size of each word reflecting its relative frequency. Key terms like “government,” “people,” “every,” “states,” and “nation” are prominently featured, highlighting the early emphasis on governance, unity, and the role of citizens in the newly formed United States. Words such as “union,” “public,” “peace,” and “country” reflect a focus on stability, collective progress, and national identity during the formative years of the republic. The use of terms like “great” and “citizens” conveys optimism and an inclusive vision for the nation. This wordcloud underscores the foundational themes and priorities of early American leadership.\n\ndata_corpus_inaugural %&gt;%\n  corpus_subset(President %in% c(\"Trump\", \"Obama\", \"Bush\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = President) %&gt;%\n  dfm_trim(min_termfreq = 5) %&gt;%\n  textplot_wordcloud(comparison = TRUE)\n\n\n\n\n\n\n\n\nThis wordcloud compares the most frequently used words in the inaugural speeches of Presidents Bush, Obama, and Trump. Common themes such as “America,” “American,” “freedom,” and “people” dominate across all three, reflecting their shared focus on national identity and unity. Differences are evident in emphasis: Bush highlights themes like “liberty” and “faith,” Obama emphasizes “journey” and “hope,” while Trump focuses on terms like “dreams,” “protected,” and “borders,” underscoring his focus on security and patriotism. The wordcloud visually captures the overlap in core themes while illustrating the unique rhetorical priorities of each president.\n\n# Subset inaugural speeches after 1949\ndata_corpus_inaugural_subset &lt;- corpus_subset(data_corpus_inaugural, Year &gt; 1949)\n\n# Examine the keyword \"american\"\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"american\") %&gt;%\n  textplot_xray()\n\n\n\n\n\n\n\n\n\nlibrary(quanteda.textstats)\n\nWarning: package 'quanteda.textstats' was built under R version 4.4.2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n# Frequency of \"american\" grouped by president\nfreq_grouped &lt;- textstat_frequency(dfm(tokens(data_corpus_inaugural_subset)), \n                                   groups = data_corpus_inaugural_subset$President)\n\nfreq_american &lt;- subset(freq_grouped, feature == \"american\")\n\n# Plot the frequency\nggplot(freq_american, aes(x = group, y = frequency)) +\n  geom_point() +\n  xlab(\"President\") +\n  ylab(\"Frequency of 'American'\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThis graph shows the frequency of the word “American” in U.S. presidential inaugural addresses, grouped by president. Bill Clinton has the highest usage, indicating a strong emphasis on national identity and values during his speeches. Joe Biden, Ronald Reagan, and Donald Trump also use the term frequently, reflecting their focus on uniting or addressing the American people. Presidents like Carter and Eisenhower have significantly lower frequencies, suggesting a different rhetorical focus. The variation highlights how different presidents prioritize national identity in their inaugural addresses, tailoring their language to the themes of their administration or the challenges of their era.\n\n# Compare Trump and Obama's speeches using keyness\npres_dfm &lt;- data_corpus_inaugural %&gt;%\n  corpus_subset(President %in% c(\"Trump\", \"Obama\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  tokens_group(groups = President) %&gt;%\n  dfm()\n\nresult_keyness &lt;- textstat_keyness(pres_dfm, target = \"Trump\")\n\n# Plot keyness results\ntextplot_keyness(result_keyness, show_reference = FALSE)\n\n\n\n\n\n\n\n\nThis graph illustrates a keyness analysis comparing the distinct language used in a target group of speeches against a reference group, based on the chi-squared (chi2) metric. The word “America” is the most distinctive, reflecting a strong focus on national identity, followed by terms like “protected” and “dreams,” which emphasize security and aspirations. Words such as “American,” “first,” and “everyone” suggest themes of inclusivity and unity, while “back” and “right” imply restoration or directional change. Other notable terms, like “country,” “foreign,” and “bring,” highlight priorities around national sovereignty, international relations, and action. The graph provides a clear depiction of the rhetorical focus of the target speeches compared to the reference group.\n\n# Wordfish model on Irish budget speeches\nie_dfm &lt;- dfm(tokens(data_corpus_irishbudget2010))\n\nwf &lt;- textmodel_wordfish(ie_dfm, dir = c(6, 5))\n\n# Plot estimated positions of words\ntextplot_scale1d(wf, margin = \"features\",\n                 highlighted = c(\"government\", \"economy\", \"budget\"),\n                 highlighted_color = \"red\")\n\n\n\n\n\n\n\n\n\n# Correspondence Analysis (CA) on Irish budget speeches\nca &lt;- textmodel_ca(ie_dfm)\n\n# Plot document positions grouped by party\ntextplot_scale1d(ca, margin = \"documents\",\n                 groups = docvars(data_corpus_irishbudget2010, \"party\"))\n\n\n\n\n\n\n\n\nThis graph visualizes the document positions of Irish budget speeches, grouped by political party (e.g., FF, Green, SF, FG, LAB), using a scaling technique (likely Wordfish or Wordscores). The positions on the horizontal axis reflect the ideological or rhetorical stance of each speaker, with negative values indicating a left-leaning or critical tone and positive values reflecting a right-leaning or supportive tone.\nFor example, the Fianna Fáil (FF) speakers, including Brian Lenihan and Brian Cowen, cluster closely together with slightly positive positions, reflecting alignment in their rhetoric. The Green Party speakers, like John Gormley and Ciaran Cuffe, are more dispersed, suggesting varied perspectives within the party. Sinn Féin (SF) speakers lean towards the negative side, indicating a critical stance. Fine Gael (FG) and Labour (LAB) members show diverse positions, with some leaning towards neutral and others more critical. This graph highlights how different parties and individuals positioned themselves rhetorically in relation to the Irish budget speeches."
  },
  {
    "objectID": "Assignments/Assignment4.html",
    "href": "Assignments/Assignment4.html",
    "title": "Assignment 4",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.2\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rvest)\n\nWarning: package 'rvest' was built under R version 4.4.2\n\n\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\nurl &lt;- 'https://en.wikipedia.org/wiki/List_of_countries_by_foreign-exchange_reserves'\nwikiforreserve &lt;- read_html(url)\n\nforeignreserve &lt;- wikiforreserve %&gt;%\n  html_nodes(xpath='//*[@id=\"mw-content-text\"]/div[1]/table[1]') %&gt;%\n  html_table()\n\nfores = foreignreserve[[1]][,c(1, 2,3,4,5,6,7,8)]\nnames(fores) &lt;- c(\"Country\", \"Forexreswithgold\", \"Date1\", \"Change1\", \"Forexreswithoutgold\", \"Date2\", \"Change2\", \"Sources\")\n\nfores$Date1 = as.Date(fores$Date1, format = \"%d %b %Y\")\n\nwrite.csv(fores, \"fores.csv\", row.names = FALSE)\n\n\nlibrary(tidyverse)\nlibrary(rvest)\n\n\nurl &lt;- 'https://en.wikipedia.org/wiki/List_of_countries_by_foreign-exchange_reserves'\n\n\nwikiforreserve &lt;- read_html(url)\n\ntables &lt;- wikiforreserve %&gt;% \n  html_nodes(\"table\") %&gt;% \n  html_table(fill = TRUE)\n\nforeign_reserve &lt;- tables[[1]]\n\ncolnames(foreign_reserve) &lt;- c(\"Country\", \"ForexResWithGold\", \"Date1\", \"Change1\", \n                               \"ForexResWithoutGold\", \"Date2\", \"Change2\", \"Source\")\nforeign_reserve$Date1 &lt;- as.Date(foreign_reserve$Date1, format = \"%d %b %Y\")\n\nwrite.csv(foreign_reserve, \"foreign_reserve.csv\", row.names = FALSE)\n\nfor (i in 2:length(tables)) {\n  table &lt;- tables[[i]]\n  write.csv(table, paste0(\"table_\", i, \".csv\"), row.names = FALSE)\n}\n\n\ngc(reset=T)\n\n          used (Mb) gc trigger  (Mb) max used (Mb)\nNcells 1043644 55.8    2116648 113.1  1043644 55.8\nVcells 1809429 13.9    8388608  64.0  1809429 13.9\n\nlibrary(purrr)\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nsetwd(\"D:\\\\Salman's Website\\\\\")\nlibrary(rjson)\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\n\nThe following objects are masked from 'package:rjson':\n\n    fromJSON, toJSON\n\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\nlibrary(data.table)\n\nWarning: package 'data.table' was built under R version 4.4.2\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(readr)\n\ngovfiles= read.csv(file=\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_10_42.csv\", skip=2)\n\ngf_list &lt;- rjson::fromJSON(file =\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_18_29.json\")\ngovfile2=dplyr::bind_rows(gf_list$resultSet)\n\ngf_list1 = jsonlite::read_json(\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_18_29.json\")\n\ngovfiles3 &lt;- gf_list1$resultSet\n\ngovfiles3 &lt;- gf_list1$resultSet |&gt; dplyr::bind_rows()\n\ngovfiles$id = govfiles$packageId\npdf_govfiles_url = govfiles$pdfLink\npdf_govfiles_id &lt;- govfiles$id\n\n\nsave_dir &lt;- \"D:\\\\Salman's Website\\\\\"\n\ndownload_govfiles_pdf &lt;- function(url, id) {\n  tryCatch({\n    destfile &lt;- paste0(save_dir, \"govfiles_\", id, \".pdf\")\n    download.file(url, destfile = destfile, mode = \"wb\") \n    Sys.sleep(runif(1, 1, 3)) \n    return(paste(\"Successfully downloaded:\", url))\n  },\n  error = function(e) {\n    return(paste(\"Failed to download:\", url))\n  })\n}\n\nstart.time &lt;- Sys.time()\nmessage(\"Starting downloads\")\n\nStarting downloads\n\nresults &lt;- 1:1 %&gt;% \n  purrr::map_chr(~ download_govfiles_pdf(pdf_govfiles_url[.], pdf_govfiles_id[.]))\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): downloaded\nlength 2764800 != reported length 424775211\n\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): URL\n'https://www.govinfo.gov/content/pkg/CPRT-95JPRT20039OvIII/pdf/CPRT-95JPRT20039OvIII.pdf':\nTimeout of 60 seconds was reached\n\nmessage(\"Finished downloads\")\n\nFinished downloads\n\nend.time &lt;- Sys.time()\ntime.taken &lt;- end.time - start.time\ntime.taken\n\nTime difference of 1.001724 mins\n\nstart.time &lt;- Sys.time()\nmessage(\"Starting downloads\")\n\nStarting downloads\n\nresults &lt;- 1:length(pdf_govfiles_url) %&gt;% \n  purrr::map_chr(~ download_govfiles_pdf(pdf_govfiles_url[.], pdf_govfiles_id[.]))\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): downloaded\nlength 13780648 != reported length 424775211\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): URL\n'https://www.govinfo.gov/content/pkg/CPRT-95JPRT20039OvIII/pdf/CPRT-95JPRT20039OvIII.pdf':\nTimeout of 60 seconds was reached\n\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): downloaded\nlength 13901606 != reported length 413579288\n\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): URL\n'https://www.govinfo.gov/content/pkg/CPRT-95JPRT20818OvI/pdf/CPRT-95JPRT20818OvI.pdf':\nTimeout of 60 seconds was reached\n\nmessage(\"Finished downloads\")\n\nFinished downloads\n\nend.time &lt;- Sys.time()\ntime.taken &lt;- end.time - start.time\ntime.taken\n\nTime difference of 2.721231 mins\n\nprint(results)\n\n[1] \"Failed to download: https://www.govinfo.gov/content/pkg/CPRT-95JPRT20039OvIII/pdf/CPRT-95JPRT20039OvIII.pdf\"\n[2] \"Failed to download: https://www.govinfo.gov/content/pkg/CPRT-95JPRT20818OvI/pdf/CPRT-95JPRT20818OvI.pdf\"    \n[3] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-109JPRT25514/pdf/CPRT-109JPRT25514.pdf\"   \n[4] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-115SPRT28545/pdf/CPRT-115SPRT28545.pdf\"   \n[5] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-115SPRT23704/pdf/CPRT-115SPRT23704.pdf\"   \n\n\nDuring the scraping process, several challenges were encountered, including inconsistent data formatting between the CSV and JSON files, missing or null values in some fields, and occasional rate-limiting during batch downloads. The scraped data is generally usable but requires preprocessing, such as cleaning column names, handling missing values, and ensuring consistency between different data sources. The extracted PDF links and metadata are valuable for further analysis, but the usability of the downloaded files depends on the quality and structure of the PDFs. To improve, we could implement better error handling, automate data cleaning steps, and optimize the download process with parallelization or by handling rate-limiting more effectively. Using tools like APIs or web drivers for dynamic content and adding validation checks for data integrity would also enhance the efficiency and reliability of the scraping process."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Salman Bin Habib",
    "section": "",
    "text": "Welcome to Habib’s website\nHi, I’m Salman Bin Habib, a second-year Ph.D. student in Public Affairs at the University of Texas at Dallas. My academic journey is deeply rooted in a passion for advancing the financial health, fundraising efficiency, and policy frameworks of nonprofit organizations and local government. By integrating rigorous research with practical applications, I aim to bridge the gap between theory and real-world challenges, driving meaningful improvements in nonprofit performance and community impact.\nMy perspective is shaped not only by academic pursuits but also by professional experience in sales and marketing within the private sector. This background has given me a unique lens to analyze organizational efficiency, resource optimization, and strategic communication—skills I now apply to nonprofit research and policy design. I believe that insights from the private sector can inspire innovative approaches to fundraising, stakeholder engagement, and financial sustainability in the nonprofit world.\nAdditionally, my research explores cutting-edge areas like blockchain policy, emphasizing its potential to revolutionize transparency and trust within the nonprofit sector. My mission is to empower organizations to thrive financially while maximizing their cultural and social contributions.\nLet’s connect and make an impact together!"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Salman Bin Habib",
    "section": "About Me",
    "text": "About Me\nI’m a proud Bengali from Dhaka, the bustling capital of Bangladesh—a small but densely populated country, with over 200 million people (more than Russia, Australia, and Canada combined!). As an only child, I’ve been both spoiled and showered with unconditional love by my amazing parents, who are my biggest cheerleaders and the foundation of everything I’ve accomplished. In 2023, I married the love of my life, Nabila Parijat, who also happens to be a fellow Ph.D. student in Public Affairs at UTD! I’m a big foodie and can never say no to fried chicken, whether it’s from Church’s, Dave’s, Jollibee, or Korean spots. When I’m not working, you’ll probably find me rewatching FRIENDS, diving into Korean movies, or enjoying long drives across the beautiful Texas. I also spend way too much time laughing at Conan O’Brien’s skits with Jordan Schlansky on YouTube. Can life BE any better than this?"
  },
  {
    "objectID": "index.html#research-projects",
    "href": "index.html#research-projects",
    "title": "Salman Bin Habib",
    "section": "Research & Projects",
    "text": "Research & Projects\nHere are some of the areas I am actively working on:\n\nNonprofit Financial Health: Investigating how financial health influences nonprofit performance and community impact.\nBlockchain and Public Policy: Understanding the implications of blockchain technology on state-level laws and nonprofit operations.\nHomelessness Migration: Analyzing migration patterns in Texas and their effects on public service delivery."
  },
  {
    "objectID": "index.html#skills-and-tools",
    "href": "index.html#skills-and-tools",
    "title": "Salman Bin Habib",
    "section": "Skills and Tools",
    "text": "Skills and Tools\n\nProgramming Languages: Python, R, STATA, SPSS\n\nData Analysis: Regression, K-means Clustering, Factor Analysis, Sentiment Analysis\n\nVisualization Tools: Power BI, Tableau, Excel"
  },
  {
    "objectID": "index.html#connect-with-me",
    "href": "index.html#connect-with-me",
    "title": "Salman Bin Habib",
    "section": "Connect with Me",
    "text": "Connect with Me\nI am always open to collaborations, discussions, and opportunities to share knowledge. Feel free to reach out!\n\nEmail: Salman.Habib@UTDallas.edu\n\nGitHub: github.com/salmanhabib01\n\nLinkedIn: linkedin.com/in/salmanbinhabib\n\n\nThank you for visiting my website! Stay tuned for updates and new projects."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download My Resume (PDF)"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "Education",
    "text": "Education\n\nPhD in Public and Nonprofit Management\nUniversity of Texas at Dallas (Aug 2023 – Jul 2027)\nGPA: 4.0/4.0\nRelevant Coursework: Research Design, Methods of Data Collection, Financial Management for Nonprofits\nMS in Marketing Research & Analysis\nTexas State University (Aug 2021 – Jul 2023)\nGPA: 3.7/4.0 | Honors: Beta Gamma Sigma\nBBA in Marketing\nNorth South University (Sept 2012 – Aug 2019)\nGPA: 3.5/4.0"
  },
  {
    "objectID": "resume.html#professional-experience",
    "href": "resume.html#professional-experience",
    "title": "Resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nTeaching Assistant\nUniversity of Texas at Dallas (Aug 2023 – Present)\nConducted data analysis for blockchain and nonprofit research; prepared visualizations and literature reviews.\nMarketing Intern\nAbracon LLC (Feb 2023 – July 2023)\nCreated promotional materials and optimized SEO for improved content performance.\nSocial Media Marketing Analyst\nTexas State University (Jun 2022 – Jan 2023)\nBoosted website traffic 10x through effective content strategies and event planning."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\nFeel free to reach out via email or connect on social media.\n\nEmail: Salman.Habib@UTDallas.edu\nGitHub: github.com/salmanhabib01\nLinkedIn: linkedin.com/in/salmanbinhabib"
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Gallery",
    "section": "",
    "text": "Nonprofit Financial Health Analysis\nBlockchain Policy Research\nHomelessness Migration Patterns in Texas"
  },
  {
    "objectID": "gallery.html#featured-projects",
    "href": "gallery.html#featured-projects",
    "title": "Gallery",
    "section": "",
    "text": "Nonprofit Financial Health Analysis\nBlockchain Policy Research\nHomelessness Migration Patterns in Texas"
  },
  {
    "objectID": "resume.html#research-experience",
    "href": "resume.html#research-experience",
    "title": "Resume",
    "section": "Research Experience",
    "text": "Research Experience\n\nExploring Homelessness Migration in Texas and Its Implications for Public Service\nPresented at ASPA Conference, Washington, DC (April 2025).\nPartisan Pathways: Exploring State-Level Politics in Blockchain and Cryptocurrency Laws\nPresented at SPSA Conference, San Juan, PR (January 2025).\nCurrency of Culture: Impacts of Charity Navigator’s ‘Culture and Community’ Beacon\nPresented at ARNOVA Conference, Washington, DC (November 2024)."
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Resume",
    "section": "Skills",
    "text": "Skills\n\nProgramming Languages: Python, R, STATA, SPSS\n\nData Analysis: Regression, K-means Clustering, Survey Design\n\nData Visualization: Power BI, Tableau, Excel"
  },
  {
    "objectID": "resume.html#honors",
    "href": "resume.html#honors",
    "title": "Resume",
    "section": "Honors",
    "text": "Honors\n\nBeta Gamma Sigma (March 2022 – Present)\n\nH.C. Vivian Memorial Endowment Scholarship (Aug 2022 – May 2023)\n\nTreasurer, Texas State Bangladesh Student Association (Oct 2022 – Aug 2023)"
  },
  {
    "objectID": "index.html#photo-reel",
    "href": "index.html#photo-reel",
    "title": "Salman Bin Habib",
    "section": "Photo Reel",
    "text": "Photo Reel\n\n\n&lt;img src=\"images/Salman and Nabila Wedding.jpg\" alt=\"Photo 1\"&gt;\n\n\n&lt;img src=\"images/Salmans Graduation Texas State University.jpg\" alt=\"Photo 2\"&gt;\n\n\n&lt;img src=\"images/Salman with Carlton.jpg\" alt=\"Photo 3\"&gt;\n\n\n&lt;img src=\"images/Salman with Parents on Wedding.jpg\" alt=\"Photo 4\"&gt;\n\n\n\n\nKey Highlights:\n\nEducation: PhD in Public and Nonprofit Management (GPA: 4.0/4.0), MS in Marketing Research & Analysis, and BBA in Marketing.\nResearch: Contributions to topics like homelessness migration, blockchain policy, and charity culture and community ratings.\nSkills: Regression analysis, sentiment analysis, data visualization, and policy evaluation.\n\nLearn more about my work →"
  }
]