[
  {
    "objectID": "Assignments/Assignment2.html",
    "href": "Assignments/Assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "library(gtrendsR)\n\nWarning: package 'gtrendsR' was built under R version 4.4.2\n\nHarrisTrumpElection &lt;- gtrends(\n  c(\"Trump\", \"Harris\", \"election\"), \n  time = \"2024-01-01 2024-10-01\"\n)\nHarris_Trump_Election_interest_over_time &lt;- HarrisTrumpElection$interest_over_time\n\ntrump_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"Trump\")\nharris_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"Harris\")\nelection_data &lt;- subset(Harris_Trump_Election_interest_over_time, keyword == \"election\")\n\npar(family = \"serif\")\nplot(\n  trump_data$date, trump_data$hits, \n  type = \"l\", col = \"blue\", \n  xlab = \"Date\", ylab = \"Search Interest\", \n  main = \"Google Trends: Trump, Harris, and Election\",\n  lwd = 2 \n)\n\nlines(\n  harris_data$date, harris_data$hits, \n  col = \"red\", lwd = 2\n)\n\nlines(\n  election_data$date, election_data$hits, \n  col = \"green\", lwd = 2\n)\n\nlegend(\n  \"topright\", legend = c(\"Trump\", \"Harris\", \"Election\"), \n  col = c(\"blue\", \"red\", \"green\"), lty = 1, lwd = 2\n)"
  },
  {
    "objectID": "Assignments/Assignment3.html",
    "href": "Assignments/Assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "library(quanteda)\n\nWarning: package 'quanteda' was built under R version 4.4.2\n\n\nPackage version: 4.1.0\nUnicode version: 15.1\nICU version: 74.1\n\n\nParallel computing: 4 of 4 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\n\nWarning: package 'quanteda.textmodels' was built under R version 4.4.2\n\nlibrary(quanteda.textplots)\n\nWarning: package 'quanteda.textplots' was built under R version 4.4.2\n\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.4.2\n\nsummit &lt;- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm &lt;- dfm(toks)\nclass(toks)\n\n[1] \"tokens\"\n\nsum_lsa &lt;- textmodel_lsa(sumtwtdfm, nd=4,  margin = c(\"both\", \"documents\", \"features\"))\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                      4 -none-    numeric\ndocs                58080 -none-    numeric\nfeatures            63972 -none-    numeric\nmatrix_low_rank 232218360 -none-    numeric\ndata            232218360 dgCMatrix S4     \n\nhead(sum_lsa$docs)\n\n              [,1]          [,2]          [,3]          [,4]\ntext1 8.670375e-03  9.539431e-03 -3.365261e-03  1.378640e-02\ntext2 8.662406e-06 -8.754517e-06 -6.159723e-06  1.673892e-05\ntext3 2.917454e-03  6.809891e-03  1.059921e-03 -3.180288e-03\ntext4 1.046103e-02  8.782783e-04 -4.359418e-03  4.941183e-03\ntext5 3.247147e-03  8.006068e-03  1.632191e-04 -4.657788e-03\ntext6 3.247147e-03  8.006068e-03  1.632191e-04 -4.657788e-03\n\nclass(sum_lsa)\n\n[1] \"textmodel_lsa\"\n\ntweet_dfm &lt;- tokens(sum_twt, remove_punct = TRUE) %&gt;%\n  dfm()\nhead(tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 15,927 features (99.89% sparse) and 0 docvars.\n       features\ndocs    breaking news us president biden amp communist china leader xi\n  text1        1    1  1         1     1   1         1     2      1  1\n  text2        0    0  0         0     0   0         0     0      0  0\n  text3        0    0  0         0     1   0         0     0      0  1\n  text4        0    0  0         1     1   0         0     0      0  1\n  text5        0    0  0         0     1   0         0     0      0  1\n  text6        0    0  0         0     1   0         0     0      0  1\n[ reached max_nfeat ... 15,917 more features ]\n\n\nThe table represents a document-feature matrix (DFM), summarizing the frequency of unique tokens (features) in six tweets (documents). Each row corresponds to a tweet, and each column represents a token. For example, in the first tweet (text1), the token biden appears once, while tokens like breaking and news also appear once. Most entries in the matrix are zeros, as only a few tokens appear in any given tweet, resulting in 99.89% sparsity. The displayed table shows only the first 10 features out of 15,927. This matrix serves as the basis for further analysis, such as extracting hashtags, mentions, or analyzing relationships between tokens.\n\ntag_dfm &lt;- dfm_select(tweet_dfm, pattern = \"#*\")\ntoptag &lt;- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"       \"#biden\"       \"#xijinping\"   \"#joebiden\"    \"#america\"    \n [6] \"#americans\"   \"#coronavirus\" \"#fentanyl\"    \"#xi\"          \"#us\"         \n\n\nThe top hashtags reflect the main themes of the Biden-Xi summit discussed on Twitter. The frequent appearance of hashtags like #china, #biden, #xijinping, and #joebiden highlights the focus on the leaders and countries involved. Hashtags such as #america, #americans, and #us indicate attention on U.S.-related topics, while #coronavirus and #fentanyl suggest discussions about global health and the drug crisis as significant issues tied to the event.\n\ntag_fcm &lt;- fcm(tag_dfm)\nhead(tag_fcm)\n\nFeature co-occurrence matrix of: 6 by 665 features.\n               features\nfeatures        #breaking #breakingnews #biden #china #usa #pray4america\n  #breaking             0             4      5      5    5             0\n  #breakingnews         0             0      4      5    4             0\n  #biden                0             0      0    443   49             0\n  #china                0             0      0      8   76             0\n  #usa                  0             0      0      0    6             0\n  #pray4america         0             0      0      0    0             0\n               features\nfeatures        #joebiden #xijinping #america #americans\n  #breaking             0          0        0          0\n  #breakingnews         0          0        0          0\n  #biden              299        370      302        295\n  #china              339        434      308        295\n  #usa                 12         15        0          0\n  #pray4america         0          0        0          0\n[ reached max_nfeat ... 655 more features ]\n\ntopgat_fcm &lt;- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 1)\n\n\n\n\n\n\n\n\nThe network graph illustrates the co-occurrence of hashtags in tweets about the Biden-Xi summit, revealing key themes and focal points of discussion. Central hashtags like #china, #biden, and #america dominate the conversation, emphasizing the prominence of U.S.-China relations. Clusters of hashtags reflect distinct topics: one group discusses international relations and issues like #coronavirus and #fentanyl, while another highlights human rights concerns with hashtags such as #uyghurs, #uyghurgenocide, and #humanrights. The connections between hashtags demonstrate the multidimensional nature of the discourse, with strong ties between geopolitical and humanitarian topics.\n\nuser_dfm &lt;- dfm_select(tweet_dfm, pattern = \"@*\")\ntopuser &lt;- names(topfeatures(user_dfm, 50))\nhead(topuser, 20)\n\n [1] \"@potus\"           \"@politico\"        \"@joebiden\"        \"@jendeben\"       \n [5] \"@eneskanter\"      \"@nwadhams\"        \"@phelimkine\"      \"@nahaltoosi\"     \n [9] \"@nba\"             \"@washwizards\"     \"@pelicansnba\"     \"@capitalonearena\"\n[13] \"@kevinliptakcnn\"  \"@foxbusiness\"     \"@morningsmaria\"   \"@scmpnews\"       \n[17] \"@petermartin_pcm\" \"@nytimes\"         \"@uyghur_american\" \"@kaylatausche\"   \n\nuser_fcm &lt;- fcm(user_dfm)\nhead(user_fcm, 20)\n\nFeature co-occurrence matrix of: 20 by 711 features.\n                 features\nfeatures          @youtube @bfmtv @cnn @lauhaim @barackobama @joebiden\n  @youtube               0      0    0        0            0         0\n  @bfmtv                 0      0    1        1            1         1\n  @cnn                   0      0    0        1            1         1\n  @lauhaim               0      0    0        0            1         1\n  @barackobama           0      0    0        0            0         1\n  @joebiden              0      0    0        0            0         3\n  @kamalaharris          0      0    0        0            0         0\n  @hillaryclinton        0      0    0        0            0         0\n  @billclinton           0      0    0        0            0         0\n  @cbsnews               0      0    0        0            0         0\n                 features\nfeatures          @kamalaharris @hillaryclinton @billclinton @cbsnews\n  @youtube                    0               0            0        0\n  @bfmtv                      1               1            1        1\n  @cnn                        1               1            1        1\n  @lauhaim                    1               1            1        1\n  @barackobama                1               1            1        1\n  @joebiden                   1               1            1        1\n  @kamalaharris               0               1            1        1\n  @hillaryclinton             0               0            1        1\n  @billclinton                0               0            0        1\n  @cbsnews                    0               0            0        0\n[ reached max_feat ... 10 more features, reached max_nfeat ... 701 more features ]\n\n\nThe table presents a feature co-occurrence matrix (FCM) of Twitter mentions, showing how frequently certain user handles (e.g., @joebiden, @cnn, @nytimes) appear together in tweets about the Biden-Xi summit. The first list highlights the top 20 most frequently mentioned user handles, including influential figures and organizations such as @potus, @joebiden, and @nytimes. The matrix shows co-occurrence counts between these handles and others, where rows and columns represent specific handles. For example, @joebiden co-occurs three times with itself, while it co-occurs once with handles like @barackobama and @cnn. Handles with no shared mentions in the dataset have zeros in their corresponding cells. This co-occurrence data reflects the focus on key public figures, media outlets, and organizations involved in discussions related to the summit, highlighting their interconnected roles in shaping the narrative.\n\nuser_fcm &lt;- fcm_select(user_fcm, pattern = topuser)\ntextplot_network(user_fcm, min_freq = 20, edge_color = \"firebrick\", edge_alpha = 0.8, edge_size = 1)\n\n\n\n\n\n\n\n\nThe network graph illustrates the co-occurrence of Twitter mentions in discussions about the Biden-Xi summit, with distinct clusters reflecting subtopics. A dense sports-related cluster includes handles like @nba, @washwizards, and @capitalonearena, possibly indicating discussions on sports diplomacy. Another cluster involving @politico, @nahaltoosi, and @phelimkine suggests political or journalistic coverage, while mentions like @foxbusiness and @morningsmaria point to economic or business-related topics. The strength of connections varies, with some pairs, such as @nba and @washwizards, showing frequent co-mentions, while smaller, isolated pairs like @learyreports and @glubold represent narrower discussions. Overall, the graph highlights the segmented yet interconnected nature of conversations around the summit.\n\ndfm_inaug &lt;- data_corpus_inaugural %&gt;%\n  corpus_subset(Year &lt;= 1826) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_trim(min_termfreq = 10)\n\nset.seed(123)  # For reproducibility\ntextplot_wordcloud(dfm_inaug, min_count = 10, \n                   color = c(\"red\", \"blue\", \"green\", \"purple\"))\n\n\n\n\n\n\n\n\nThis wordcloud visualizes the most frequently used words in U.S. presidential inaugural addresses from 1789 to 1826, with the size of each word reflecting its relative frequency. Key terms like “government,” “people,” “every,” “states,” and “nation” are prominently featured, highlighting the early emphasis on governance, unity, and the role of citizens in the newly formed United States. Words such as “union,” “public,” “peace,” and “country” reflect a focus on stability, collective progress, and national identity during the formative years of the republic. The use of terms like “great” and “citizens” conveys optimism and an inclusive vision for the nation. This wordcloud underscores the foundational themes and priorities of early American leadership.\n\ndata_corpus_inaugural %&gt;%\n  corpus_subset(President %in% c(\"Trump\", \"Obama\", \"Bush\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() %&gt;%\n  dfm_group(groups = President) %&gt;%\n  dfm_trim(min_termfreq = 5) %&gt;%\n  textplot_wordcloud(comparison = TRUE)\n\n\n\n\n\n\n\n\nThis wordcloud compares the most frequently used words in the inaugural speeches of Presidents Bush, Obama, and Trump. Common themes such as “America,” “American,” “freedom,” and “people” dominate across all three, reflecting their shared focus on national identity and unity. Differences are evident in emphasis: Bush highlights themes like “liberty” and “faith,” Obama emphasizes “journey” and “hope,” while Trump focuses on terms like “dreams,” “protected,” and “borders,” underscoring his focus on security and patriotism. The wordcloud visually captures the overlap in core themes while illustrating the unique rhetorical priorities of each president.\n\n# Subset inaugural speeches after 1949\ndata_corpus_inaugural_subset &lt;- corpus_subset(data_corpus_inaugural, Year &gt; 1949)\n\n# Examine the keyword \"american\"\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"american\") %&gt;%\n  textplot_xray()\n\n\n\n\n\n\n\n\n\nlibrary(quanteda.textstats)\n\nWarning: package 'quanteda.textstats' was built under R version 4.4.2\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n# Frequency of \"american\" grouped by president\nfreq_grouped &lt;- textstat_frequency(dfm(tokens(data_corpus_inaugural_subset)), \n                                   groups = data_corpus_inaugural_subset$President)\n\nfreq_american &lt;- subset(freq_grouped, feature == \"american\")\n\n# Plot the frequency\nggplot(freq_american, aes(x = group, y = frequency)) +\n  geom_point() +\n  xlab(\"President\") +\n  ylab(\"Frequency of 'American'\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThis graph shows the frequency of the word “American” in U.S. presidential inaugural addresses, grouped by president. Bill Clinton has the highest usage, indicating a strong emphasis on national identity and values during his speeches. Joe Biden, Ronald Reagan, and Donald Trump also use the term frequently, reflecting their focus on uniting or addressing the American people. Presidents like Carter and Eisenhower have significantly lower frequencies, suggesting a different rhetorical focus. The variation highlights how different presidents prioritize national identity in their inaugural addresses, tailoring their language to the themes of their administration or the challenges of their era.\n\n# Compare Trump and Obama's speeches using keyness\npres_dfm &lt;- data_corpus_inaugural %&gt;%\n  corpus_subset(President %in% c(\"Trump\", \"Obama\")) %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  tokens_group(groups = President) %&gt;%\n  dfm()\n\nresult_keyness &lt;- textstat_keyness(pres_dfm, target = \"Trump\")\n\n# Plot keyness results\ntextplot_keyness(result_keyness, show_reference = FALSE)\n\n\n\n\n\n\n\n\nThis graph illustrates a keyness analysis comparing the distinct language used in a target group of speeches against a reference group, based on the chi-squared (chi2) metric. The word “America” is the most distinctive, reflecting a strong focus on national identity, followed by terms like “protected” and “dreams,” which emphasize security and aspirations. Words such as “American,” “first,” and “everyone” suggest themes of inclusivity and unity, while “back” and “right” imply restoration or directional change. Other notable terms, like “country,” “foreign,” and “bring,” highlight priorities around national sovereignty, international relations, and action. The graph provides a clear depiction of the rhetorical focus of the target speeches compared to the reference group.\n\n# Wordfish model on Irish budget speeches\nie_dfm &lt;- dfm(tokens(data_corpus_irishbudget2010))\n\nwf &lt;- textmodel_wordfish(ie_dfm, dir = c(6, 5))\n\n# Plot estimated positions of words\ntextplot_scale1d(wf, margin = \"features\",\n                 highlighted = c(\"government\", \"economy\", \"budget\"),\n                 highlighted_color = \"red\")\n\n\n\n\n\n\n\n\n\n# Correspondence Analysis (CA) on Irish budget speeches\nca &lt;- textmodel_ca(ie_dfm)\n\n# Plot document positions grouped by party\ntextplot_scale1d(ca, margin = \"documents\",\n                 groups = docvars(data_corpus_irishbudget2010, \"party\"))\n\n\n\n\n\n\n\n\nThis graph visualizes the document positions of Irish budget speeches, grouped by political party (e.g., FF, Green, SF, FG, LAB), using a scaling technique (likely Wordfish or Wordscores). The positions on the horizontal axis reflect the ideological or rhetorical stance of each speaker, with negative values indicating a left-leaning or critical tone and positive values reflecting a right-leaning or supportive tone.\nFor example, the Fianna Fáil (FF) speakers, including Brian Lenihan and Brian Cowen, cluster closely together with slightly positive positions, reflecting alignment in their rhetoric. The Green Party speakers, like John Gormley and Ciaran Cuffe, are more dispersed, suggesting varied perspectives within the party. Sinn Féin (SF) speakers lean towards the negative side, indicating a critical stance. Fine Gael (FG) and Labour (LAB) members show diverse positions, with some leaning towards neutral and others more critical. This graph highlights how different parties and individuals positioned themselves rhetorically in relation to the Irish budget speeches."
  },
  {
    "objectID": "Assignments/Assignment4.html",
    "href": "Assignments/Assignment4.html",
    "title": "Assignment4",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'ggplot2' was built under R version 4.4.2\n\n\nWarning: package 'tibble' was built under R version 4.4.2\n\n\nWarning: package 'tidyr' was built under R version 4.4.2\n\n\nWarning: package 'readr' was built under R version 4.4.2\n\n\nWarning: package 'purrr' was built under R version 4.4.2\n\n\nWarning: package 'dplyr' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rvest)\n\nWarning: package 'rvest' was built under R version 4.4.2\n\n\n\nAttaching package: 'rvest'\n\nThe following object is masked from 'package:readr':\n\n    guess_encoding\n\nurl &lt;- 'https://en.wikipedia.org/wiki/List_of_countries_by_foreign-exchange_reserves'\nwikiforreserve &lt;- read_html(url)\n\nforeignreserve &lt;- wikiforreserve %&gt;%\n  html_nodes(xpath='//*[@id=\"mw-content-text\"]/div[1]/table[1]') %&gt;%\n  html_table()\n\nfores = foreignreserve[[1]][,c(1, 2,3,4,5,6,7,8)]\nnames(fores) &lt;- c(\"Country\", \"Forexreswithgold\", \"Date1\", \"Change1\", \"Forexreswithoutgold\", \"Date2\", \"Change2\", \"Sources\")\n\nfores$Date1 = as.Date(fores$Date1, format = \"%d %b %Y\")\n\nwrite.csv(fores, \"fores.csv\", row.names = FALSE)\n\n\nlibrary(tidyverse)\nlibrary(rvest)\n\n\nurl &lt;- 'https://en.wikipedia.org/wiki/List_of_countries_by_foreign-exchange_reserves'\n\n\nwikiforreserve &lt;- read_html(url)\n\ntables &lt;- wikiforreserve %&gt;% \n  html_nodes(\"table\") %&gt;% \n  html_table(fill = TRUE)\n\nforeign_reserve &lt;- tables[[1]]\n\ncolnames(foreign_reserve) &lt;- c(\"Country\", \"ForexResWithGold\", \"Date1\", \"Change1\", \n                               \"ForexResWithoutGold\", \"Date2\", \"Change2\", \"Source\")\nforeign_reserve$Date1 &lt;- as.Date(foreign_reserve$Date1, format = \"%d %b %Y\")\n\nwrite.csv(foreign_reserve, \"foreign_reserve.csv\", row.names = FALSE)\n\nfor (i in 2:length(tables)) {\n  table &lt;- tables[[i]]\n  write.csv(table, paste0(\"table_\", i, \".csv\"), row.names = FALSE)\n}\n\n\ngc(reset=T)\n\n          used (Mb) gc trigger  (Mb) max used (Mb)\nNcells 1043608 55.8    2116598 113.1  1043608 55.8\nVcells 1809108 13.9    8388608  64.0  1809108 13.9\n\nlibrary(purrr)\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nsetwd(\"D:\\\\Salman's Website\\\\\")\nlibrary(rjson)\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\n\nThe following objects are masked from 'package:rjson':\n\n    fromJSON, toJSON\n\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\nlibrary(data.table)\n\nWarning: package 'data.table' was built under R version 4.4.2\n\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nlibrary(readr)\n\ngovfiles= read.csv(file=\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_10_42.csv\", skip=2)\n\ngf_list &lt;- rjson::fromJSON(file =\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_18_29.json\")\ngovfile2=dplyr::bind_rows(gf_list$resultSet)\n\ngf_list1 = jsonlite::read_json(\"https://github.com/datageneration/datamethods/raw/refs/heads/master/webdata/govinfo-search-results-2024-10-13T07_18_29.json\")\n\ngovfiles3 &lt;- gf_list1$resultSet\n\ngovfiles3 &lt;- gf_list1$resultSet |&gt; dplyr::bind_rows()\n\ngovfiles$id = govfiles$packageId\npdf_govfiles_url = govfiles$pdfLink\npdf_govfiles_id &lt;- govfiles$id\n\n\nsave_dir &lt;- \"D:\\\\Salman's Website\\\\\"\n\ndownload_govfiles_pdf &lt;- function(url, id) {\n  tryCatch({\n    destfile &lt;- paste0(save_dir, \"govfiles_\", id, \".pdf\")\n    download.file(url, destfile = destfile, mode = \"wb\") \n    Sys.sleep(runif(1, 1, 3)) \n    return(paste(\"Successfully downloaded:\", url))\n  },\n  error = function(e) {\n    return(paste(\"Failed to download:\", url))\n  })\n}\n\nstart.time &lt;- Sys.time()\nmessage(\"Starting downloads\")\n\nStarting downloads\n\nresults &lt;- 1:1 %&gt;% \n  purrr::map_chr(~ download_govfiles_pdf(pdf_govfiles_url[.], pdf_govfiles_id[.]))\nmessage(\"Finished downloads\")\n\nFinished downloads\n\nend.time &lt;- Sys.time()\ntime.taken &lt;- end.time - start.time\ntime.taken\n\nTime difference of 1.011557 mins\n\nstart.time &lt;- Sys.time()\nmessage(\"Starting downloads\")\n\nStarting downloads\n\nresults &lt;- 1:length(pdf_govfiles_url) %&gt;% \n  purrr::map_chr(~ download_govfiles_pdf(pdf_govfiles_url[.], pdf_govfiles_id[.]))\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): downloaded\nlength 144830998 != reported length 424775211\n\n\nWarning in download.file(url, destfile = destfile, mode = \"wb\"): URL\n'https://www.govinfo.gov/content/pkg/CPRT-95JPRT20039OvIII/pdf/CPRT-95JPRT20039OvIII.pdf':\nTimeout of 60 seconds was reached\n\nmessage(\"Finished downloads\")\n\nFinished downloads\n\nend.time &lt;- Sys.time()\ntime.taken &lt;- end.time - start.time\ntime.taken\n\nTime difference of 2.12333 mins\n\nprint(results)\n\n[1] \"Failed to download: https://www.govinfo.gov/content/pkg/CPRT-95JPRT20039OvIII/pdf/CPRT-95JPRT20039OvIII.pdf\" \n[2] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-95JPRT20818OvI/pdf/CPRT-95JPRT20818OvI.pdf\"\n[3] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-109JPRT25514/pdf/CPRT-109JPRT25514.pdf\"    \n[4] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-115SPRT28545/pdf/CPRT-115SPRT28545.pdf\"    \n[5] \"Successfully downloaded: https://www.govinfo.gov/content/pkg/CPRT-115SPRT23704/pdf/CPRT-115SPRT23704.pdf\"    \n\n\nDuring the scraping process, several challenges were encountered, including inconsistent data formatting between the CSV and JSON files, missing or null values in some fields, and occasional rate-limiting during batch downloads. The scraped data is generally usable but requires preprocessing, such as cleaning column names, handling missing values, and ensuring consistency between different data sources. The extracted PDF links and metadata are valuable for further analysis, but the usability of the downloaded files depends on the quality and structure of the PDFs. To improve, we could implement better error handling, automate data cleaning steps, and optimize the download process with parallelization or by handling rate-limiting more effectively. Using tools like APIs or web drivers for dynamic content and adding validation checks for data integrity would also enhance the efficiency and reliability of the scraping process."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Photo of Salman Bin Habib\n\n\nHello! I’m Salman Bin Habib, a dedicated PhD candidate in Public and Nonprofit Management at the University of Texas at Dallas, with a sharp focus on nonprofit financial health, fundraising efficiency, and blockchain policy. My work blends rigorous academic research with real-world applications to improve nonprofit performance and community impact.\n\n\n\nWith a robust foundation in both qualitative and quantitative research, I specialize in: - Measuring fundraising efficiency and nonprofit financial health. - Utilizing advanced data analysis tools, including Python, R, SPSS, and STATA. - Exploring the intersection of technology, policy, and public service, such as blockchain’s impact on nonprofit management.\nMy research and professional journey are driven by a passion for creating innovative solutions to public and nonprofit sector challenges.\n\n\n\nEducation: PhD in Public and Nonprofit Management (GPA: 4.0/4.0), MS in Marketing Research & Analysis, and BBA in Marketing.\nResearch: Contributions to topics like homelessness migration, blockchain policy, and charity culture and community ratings.\nSkills: Regression analysis, sentiment analysis, data visualization, and policy evaluation.\n\nLearn more about my work →\n\n\n\n\n\nHere are some of the areas I am actively working on: 1. Nonprofit Financial Health: Investigating how financial health influences nonprofit performance and community impact. 2. Blockchain and Public Policy: Understanding the implications of blockchain technology on state-level laws and nonprofit operations. 3. Homelessness Migration: Analyzing migration patterns in Texas and their effects on public service delivery.\n\n\n\n\n\nProgramming Languages: Python, R, STATA, SPSS\nData Analysis: Regression, K-means Clustering, Factor Analysis, Sentiment Analysis\nVisualization Tools: Power BI, Tableau, Excel\n\n\n\n\n\nI am always open to collaborations, discussions, and opportunities to share knowledge. Feel free to reach out!\n\nEmail: Salman.Habib@UTDallas.edu\n\nGitHub: github.com/salmanhabib01\n\nLinkedIn: linkedin.com/in/salmanbinhabib\n\n\nThank you for visiting my website! Stay tuned for updates and new projects."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "About",
    "section": "",
    "text": "With a robust foundation in both qualitative and quantitative research, I specialize in: - Measuring fundraising efficiency and nonprofit financial health. - Utilizing advanced data analysis tools, including Python, R, SPSS, and STATA. - Exploring the intersection of technology, policy, and public service, such as blockchain’s impact on nonprofit management.\nMy research and professional journey are driven by a passion for creating innovative solutions to public and nonprofit sector challenges.\n\n\n\nEducation: PhD in Public and Nonprofit Management (GPA: 4.0/4.0), MS in Marketing Research & Analysis, and BBA in Marketing.\nResearch: Contributions to topics like homelessness migration, blockchain policy, and charity culture and community ratings.\nSkills: Regression analysis, sentiment analysis, data visualization, and policy evaluation.\n\nLearn more about my work →"
  },
  {
    "objectID": "index.html#research-projects",
    "href": "index.html#research-projects",
    "title": "About",
    "section": "",
    "text": "Here are some of the areas I am actively working on: 1. Nonprofit Financial Health: Investigating how financial health influences nonprofit performance and community impact. 2. Blockchain and Public Policy: Understanding the implications of blockchain technology on state-level laws and nonprofit operations. 3. Homelessness Migration: Analyzing migration patterns in Texas and their effects on public service delivery."
  },
  {
    "objectID": "index.html#skills-and-tools",
    "href": "index.html#skills-and-tools",
    "title": "About",
    "section": "",
    "text": "Programming Languages: Python, R, STATA, SPSS\nData Analysis: Regression, K-means Clustering, Factor Analysis, Sentiment Analysis\nVisualization Tools: Power BI, Tableau, Excel"
  },
  {
    "objectID": "index.html#connect-with-me",
    "href": "index.html#connect-with-me",
    "title": "About",
    "section": "",
    "text": "I am always open to collaborations, discussions, and opportunities to share knowledge. Feel free to reach out!\n\nEmail: Salman.Habib@UTDallas.edu\n\nGitHub: github.com/salmanhabib01\n\nLinkedIn: linkedin.com/in/salmanbinhabib\n\n\nThank you for visiting my website! Stay tuned for updates and new projects."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download My Resume (PDF)\n\n\n\nPhD in Public and Nonprofit Management\nUniversity of Texas at Dallas\n\n\n\n\n\nTeaching Assistant\nConducted research on blockchain policy and nonprofit finance."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "",
    "text": "PhD in Public and Nonprofit Management\nUniversity of Texas at Dallas"
  },
  {
    "objectID": "resume.html#professional-experience",
    "href": "resume.html#professional-experience",
    "title": "Resume",
    "section": "",
    "text": "Teaching Assistant\nConducted research on blockchain policy and nonprofit finance."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\nFeel free to reach out via email or connect on social media.\n\nEmail: Salman.Habib@UTDallas.edu\nGitHub: github.com/salmanhabib01\nLinkedIn: linkedin.com/in/salmanbinhabib"
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Gallery",
    "section": "",
    "text": "Nonprofit Financial Health Analysis\nBlockchain Policy Research\nHomelessness Migration Patterns in Texas"
  },
  {
    "objectID": "gallery.html#featured-projects",
    "href": "gallery.html#featured-projects",
    "title": "Gallery",
    "section": "",
    "text": "Nonprofit Financial Health Analysis\nBlockchain Policy Research\nHomelessness Migration Patterns in Texas"
  }
]